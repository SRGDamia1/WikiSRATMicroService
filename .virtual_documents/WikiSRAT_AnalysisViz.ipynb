# packages for data requests
import requests
import pandas as pd
from requests.auth import HTTPBasicAuth
import json
import os
import psycopg2

from pathlib import Path

# packages for viz 
import matplotlib
import matplotlib.pyplot as plt
# from pynhd import NLDI, WaterData, NHDPlusHR
# import pynhd as nhd
# import spatialpandas as spd
# import spatialpandas.io
# import pygeos
import geopandas as gpd
import plotly.express as px

import contextily as ctx
import numpy as np

# import holoviews as hv
# import datashader as ds
# import geoviews as gv
# import geoviews.feature as gf
# from geoviews import opts
# from cartopy import crs 
# import geoviews.tile_sources as gts
# gv.extension('bokeh', 'matplotlib')
# import hvplot.pandas



print("Geopandas: ", gpd.__version__)
# print("spatialpandas: ", spd.__version__)
# print("datashader: ", ds.__version__)
# print("pygeos: ", pygeos.__version__)


# Find current working directory
Path.cwd()


# Use relative path - will work for anybody in this directory / cloning the github
data_folder    = Path('data/')


get_ipython().run_cell_magic("time", "", """# read data from parquet files
base_catch_gdf = gpd.read_parquet(data_folder /'base_df_catch.parquet')
base_reach_gdf = gpd.read_parquet(data_folder /'base_df_reach.parquet')

rest_catch_gdf = gpd.read_parquet(data_folder /'rest_df_catch.parquet')
rest_reach_gdf = gpd.read_parquet(data_folder /'rest_df_reach.parquet')

point_src_gdf = gpd.read_parquet(data_folder /'point_source_df.parquet')

proj_prot_gdf = gpd.read_parquet(data_folder /'prot_proj_df.parquet')
proj_rest_gdf = gpd.read_parquet(data_folder /'rest_proj_df.parquet')""")


# Confirm files are read properly
base_catch_gdf.info()


rest_catch_gdf.info()


base_reach_gdf.info()


rest_reach_gdf.info()


proj_rest_gdf.info()


# base_catch_gdf['geom_catchment'] = base_catch_gdf['geom_catchment'].buffer(0.0001)


get_ipython().run_cell_magic("time", "", """clusters = base_catch_gdf.dissolve(by='cluster')
focus_areas = base_catch_gdf.dissolve(by='fa_name')""")


# Check CRS, which appears preserved in Parquet file metadata.
base_catch_gdf.crs


get_ipython().run_cell_magic("time", "", """# Test method to reproject CRS to WGS84, which is useful for visualization
base_catch_gdf.to_crs(epsg=4326, inplace=True)""")


# Check CRS
base_catch_gdf.crs


get_ipython().run_cell_magic("time", "", """# Automate method to reproject CRS to WGS84, for all GeoDataFrames
gdfs = [base_catch_gdf, base_reach_gdf, rest_catch_gdf, rest_reach_gdf, point_src_gdf, proj_prot_gdf, proj_rest_gdf, clusters,focus_areas]

for gdf in gdfs:
    gdf.to_crs(epsg=4326, inplace=True)""")


# check that it worked
point_src_gdf.crs


# Example selecting by comid, which is the row index
base_reach_gdf.loc[4648450]


base_catch_gdf.loc[4648450]


# Annual Areal Loading Rate, for Total Phosphorus (kg/ha)
base_catch_gdf.loc[4648450].tp_load / base_catch_gdf.loc[4648450].catchment_hectares 


# Basic selection by column name
var = 'tp_load'
rest_catch_gdf[var]


# Select Series by attribute
base_catch_gdf.tp_load


# Calculate statistics for a data series
base_catch_gdf.tp_load.min()


base_catch_gdf.tp_load.max()


# Calculate statistics for a data series, filtered by a categorical column.
base_reach_gdf[base_reach_gdf.cluster=='drb'].tp_conc.mean()


# # Explict use of Pandas/GeoPandas functionality

# base_catch_gdf['tp_loadrate']  = base_catch_gdf.tp_load /  base_catch_gdf.catchment_hectares 
# base_catch_gdf['tn_loadrate']  = base_catch_gdf.tn_load /  base_catch_gdf.catchment_hectares 
# base_catch_gdf['tss_loadrate'] = base_catch_gdf.tss_load / base_catch_gdf.catchment_hectares 


# Define a function to loop through all the pollutants in a data frame
# for speed and ease that can also be applied to restoration dataframes.

def CalcLoadRate(df):
    for pollutant in ['tp', 'tn', 'tss']:
        df['%s_loadrate' % pollutant] = df['%s_load' % pollutant] / df.catchment_hectares
    return df


# Apply to the base model run catchments
base_catch_gdf = CalcLoadRate(base_catch_gdf)


# Confirm values in Model My Watershed, from https://modelmywatershed.org/project/36183/
base_catch_gdf.loc[4648450].tp_loadrate


base_catch_gdf.loc[4648450].tn_loadrate


base_catch_gdf.loc[4648450].tss_loadrate


base_catch_gdf.info()


# Apply to the restoration model run catchments
rest_catch_gdf = CalcLoadRate(rest_catch_gdf)


rest_catch_gdf.info()


diff_df = base_catch_gdf.tp_load == rest_catch_gdf.tp_load
diff_df.value_counts()


diff_df = base_reach_gdf.tp_conc == rest_reach_gdf.tp_conc
diff_df.value_counts()


# Drop NaN values, which show up as False in comparisions
diff_df = base_reach_gdf.tp_conc.dropna() == rest_reach_gdf.tp_conc.dropna()
diff_df.value_counts()


# Threshold/Target Values for Acceptable Water Quality

# Catchment Target Load Rate (kg/ha)
tp_loadrate_target  = 0.31
tn_loadrate_target  = 11.38
tss_loadrate_target = 923.80

# Reach Target Concenctration (mg/l)
tp_conc_target  = 0.09
tn_conc_target  = 3.15
tss_conc_target = 237.30


# Create a dictionary of these Targets, to use later for iterating functions

targets = {'tp':  {'loadrate_target':tp_loadrate_target,
                   'conc_target': tp_conc_target},
           'tn':  {'loadrate_target':tn_loadrate_target,
                   'conc_target': tn_conc_target},
           'tss': {'loadrate_target':tss_loadrate_target,
                   'conc_target': tss_conc_target}
          }


targets['tp']


targets['tp']['conc_target']


# # Explict use of Pandas/GeoPandas functionality

# # Create new columns
# base_catch_gdf['tp_loadrate_xs']  = base_catch_gdf.tp_loadrate  -  tp_loadrate_target
# base_catch_gdf['tn_loadrate_xs']  = base_catch_gdf.tn_loadrate  -  tn_loadrate_target
# base_catch_gdf['tss_loadrate_xs'] = base_catch_gdf.tss_loadrate -  tss_loadrate_target


# Define a function to loop through all the pollutants in a data frame
def CalcExcessLoadRate(df, targ_dict):
    for pollutant in ['tp', 'tn', 'tss']:
        df['%s_loadrate_xs' % pollutant] = df['%s_loadrate' % pollutant] - targ_dict[pollutant]['loadrate_target']
    return df


base_catch_gdf = CalcExcessLoadRate(base_catch_gdf, targets)


base_catch_gdf.info()


# Confirm calculation relative to Model My Watershed
base_catch_gdf.loc[4648450].tp_loadrate


base_catch_gdf.loc[4648450].tp_loadrate_xs


# Difference should equal target value
targets['tp']['loadrate_target']


# # Explict use of Pandas/GeoPandas functionality

# # Create new columns
# base_gdf_proj['tp_conc_xs']  = base_gdf_proj.tp_conc  -  tp_conc_target
# base_gdf_proj['tn_conc_xs']  = base_gdf_proj.tn_conc  -  tn_conc_target
# base_gdf_proj['tss_conc_xs'] = base_gdf_proj.tss_conc -  tss_conc_target


# Define a function to loop through all the pollutants in a data frame
def CalcExcessConcs(df, targ_dict):
    for pollutant in ['tp', 'tn', 'tss']:
        df['%s_conc_xs' % pollutant] = df['%s_conc' % pollutant] - targ_dict[pollutant]['conc_target']
    return df


base_reach_gdf = CalcExcessConcs(base_reach_gdf, targets)


base_reach_gdf.info()


base_reach_gdf.loc[4648450].tp_conc


base_reach_gdf.loc[4648450].tp_conc_xs


point_src_gdf


point_src_gdf.info()


# Confirm values relative to Model My Watershed, using Analyze tab.
# Use Upper West Branch Brandywine Creek, HUC-12 (020402050202). https://modelmywatershed.org/project/36183/.

point_src_gdf.loc['PA0026859']


# Look at all point sources in this COMID
point_src_gdf[point_src_gdf['comid']==932040160]


# Many COMID's have more than one NPDES-permitted point source
point_src_gdf.comid.value_counts()


# Sum loads by COMID groups
# Non-summable dtypes (object, category, geometry) will be dropped automatically
temp_df = point_src_gdf.groupby('comid').sum()

# Other fields that should not be summed, such as lat/lon or concentrations, need to dropped explicitly
point_src_loads_comid_df = temp_df.drop(['ogc_fid',
                                         'latitude',
                                         'longitude',
                                         'avg_n_conc',
                                         'avgpconc',
                                        ], axis=1) 
point_src_loads_comid_df


# Confirm values relative to Model My Watershed, using Model tab.
# Use Upper West Branch Brandywine Creek, HUC-12 (020402050202). https://modelmywatershed.org/project/36183/.

# **These values are bigger than the MMW Model totals for COMID!**
point_src_loads_comid_df.loc[932040160]


## These values are match the MMW totals for COMID!
base_catch_gdf.tn_load.loc[932040160]


## These values are match the MMW totals for COMID!
base_catch_gdf.tp_load.loc[932040160]


# Nitrogen attenuation, fraction not retained
base_catch_gdf.tn_load.loc[932040160] / point_src_loads_comid_df.kgn_yr.loc[932040160]


# Phosphorus attenuation, fraction not retained
base_catch_gdf.tp_load.loc[932040160] / point_src_loads_comid_df.kgp_yr.loc[932040160]


# # Explict use of Pandas/GeoPandas functionality

base_catch_gdf['tp_load_ps'] = point_src_loads_comid_df.kgp_yr 
base_catch_gdf['tn_load_ps'] = point_src_loads_comid_df.kgn_yr


base_catch_gdf[['tp_load','tp_load_ps']].loc[932040160]


base_catch_gdf[['tp_load','tp_load_ps']].loc[4648450]


# Arithmetric with a NaN produces NaN!
base_catch_gdf['tp_load'].loc[4648450] - base_catch_gdf['tp_load_ps'].loc[4648450]


base_catch_gdf[['tp_load_ps','tn_load_ps']] = base_catch_gdf[['tp_load_ps','tn_load_ps']].fillna(0)


base_catch_gdf[['tp_load','tp_load_ps']].loc[4648450]


base_catch_gdf.info()


temp_df = base_catch_gdf.groupby('huc12').sum()
temp_df.head(3)


# Confirm values relative to Model My Watershed, using Model tab.
# Use Upper West Branch Brandywine Creek, HUC-12 (020402050202). https://modelmywatershed.org/project/36183/.

temp_df.loc['020402050202']


# Nitrogen
20689.0 / temp_df.loc['020402050202'].tn_load_ps


# Phosphorus
1377.0 / temp_df.loc['020402050202'].tp_load_ps


# # Explict use of Pandas/GeoPandas functionality

# base_catch_gdf['tp_loadrate_xs']  = base_catch_gdf.tp_loadrate  -  tp_loadrate_target

base_catch_gdf['tp_loadrate_xsnps']  = ((base_catch_gdf.tp_load - base_catch_gdf.tp_load_ps
                                        )  / base_catch_gdf.catchment_hectares
                                       ) - tp_loadrate_target
base_catch_gdf['tn_loadrate_xsnps']  = ((base_catch_gdf.tn_load - base_catch_gdf.tn_load_ps
                                        )  / base_catch_gdf.catchment_hectares
                                       ) - tp_loadrate_target
# TSS doesn't come from NPDES point sources


base_catch_gdf.info()


base_catch_gdf[['tp_loadrate',
                'tp_loadrate_xs',
                'tp_loadrate_xsnps',
               ]].loc[4648450]


base_catch_gdf[['tp_loadrate',
                'tp_loadrate_xs',
                'tp_loadrate_xsnps',
               ]].loc[932040160]











get_ipython().run_cell_magic("time", "", """fig, (ax1, ax2) = plt.subplots(1,2)
base_reach_gdf.plot(lw=1, ax=ax1)
base_catch_gdf.plot(lw=0.1, ax=ax2)
fig.set_size_inches(12,12)
ax1.set_title("Reaches")
ax2.set_title("Catchments")
for ax in [ax1, ax2]:
    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=base_reach_gdf.crs.to_string(), zoom=7)
plt.show()""")





def CalcMinMax(reach_df, catch_df, var_reach, var_catch):
    vmin = min(reach_df[reach_df[var_reach] > 0][var_reach].min(), catch_df[catch_df[var_catch] > 0][var_catch].min())
    vmax = max(reach_df[var_reach].max(), catch_df[var_catch].max())
    return vmin, vmax


# https://stackoverflow.com/questions/48625475/python-shifted-logarithmic-colorbar-white-color-offset-to-center
# centers logscale colorbar around provided value 
from  matplotlib.colors import LogNorm

class MidPointLogNorm(LogNorm):
    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):
        LogNorm.__init__(self,vmin=vmin, vmax=vmax, clip=clip)
        self.midpoint=midpoint
    def __call__(self, value, clip=None):
        # I'm ignoring masked values and all kinds of edge cases to make a
        # simple example...
        x, y = [np.log(self.vmin), np.log(self.midpoint), np.log(self.vmax)], [0, 0.5, 1]
        return np.ma.masked_array(np.interp(np.log(value), x, y))


focus_areas.loc[base_catch_gdf.fa_name.unique().dropna()[0:1], :]


def PlotMaps(df_reach, df_catch, var_reach, var_catch, targ_reach, targ_catch, cl=None, fa=False, zoom=False):
    # calculate min and max
    # vmin, vmax = CalcMinMax(df_reach, df_catch, var_reach, var_catch)

    # initialize figure
    fig, (ax1, ax2) = plt.subplots(1,2)
    # ax3 = fig.add_axes([0.85, 0.1, 0.1, 0.8])
    
    
    #plot reach and catchment
    # normalize around target with MidPointLogNorm
    r = df_reach.plot(column=var_reach, lw=1, ax=ax1,
                      norm= MidPointLogNorm(vmin=df_reach[var_reach].min(),
                                            vmax=df_reach[var_reach].max(),
                                            midpoint=targ_reach),
                      cmap = 'RdYlGn_r')# matplotlib.colors.LogNorm(vmin, vmax), cmap='RdYlGn_r')
    c = df_catch.plot(column=var_catch, lw=0.1, ax=ax2, 
                      norm= MidPointLogNorm(vmin=df_catch[var_catch].min(),
                                            vmax=df_catch[var_catch].max(),
                                            midpoint=targ_catch),
                      cmap='RdYlGn_r')

    # plot cluster, if applicable
    if cl != None:
        # plot cluster
        cl_reach = clusters[clusters.index == cl].plot(lw=1, ax=ax1, facecolor="none", edgecolor="black", zorder=10)
        cl_catch = clusters[clusters.index == cl].plot(lw=1, ax=ax2, facecolor="none", edgecolor="black")
    
    # plot focus areas within clusters
    if fa == True:
        fas = df_catch[df_catch.cluster == cl]['fa_name'].unique().dropna()
        fas_in_cluster = focus_areas.loc[fas, :]
        fa_reach = fas_in_cluster.plot(lw=0.7, ax = ax1, facecolor="none", edgecolor="grey", zorder=10)
        fa_catch = fas_in_cluster.plot(lw=0.7, ax=ax2, facecolor = "none", edgecolor="grey")

    # set figure size 
    fig.set_size_inches(12,12)
    # zoom in to cluster if zoom = True 
    if zoom == True:
        if cl == None:
            print("No cluster entered!")
        else:
            lon_max, lon_min, lat_max, lat_min = LatLonExtent(cl)
            for ax in [ax1, ax2]:
                ax.set_ylim(lat_min[0], lat_max[0])
                ax.set_xlim(lon_min[0], lon_max[0])
    else:
        for ax in [ax1, ax2]:
            ax.set_ylim(38.5, 42.5)
            ax.set_xlim(-76.5, -74.0)

    
    
    # set axis titles
    ax1.set_title(var_reach + " for Reaches")
    ax2.set_title(var_catch + " for Catchments")

    # add colorbar - catchment 
    cax = fig.add_axes([0.95, 0.21, 0.02, 0.58]) # adjusts the position of the color bar: right position, bottom, width, top 
    sm = plt.cm.ScalarMappable(cmap='RdYlGn_r', 
                               norm= MidPointLogNorm(vmin=df_catch[var_catch].min(),
                                                     vmax=df_catch[var_catch].max(),
                                                     midpoint=targ_catch)) # matplotlib.colors.LogNorm(vmin=vmin, vmax=vmax,),)
    cbr = fig.colorbar(sm, cax=cax,)
    cbr.ax.tick_params(labelsize=8)
    cbr.ax.minorticks_off()

    # add colorbar - reach
    cax2 = fig.add_axes([0.47, 0.21, 0.02, 0.58]) # adjusts the position of the color bar: right position, bottom, width, top 
    sm2 = plt.cm.ScalarMappable(cmap='RdYlGn_r',
                               norm=MidPointLogNorm(vmin=df_reach[var_reach].min(),
                                                    vmax=df_reach[var_reach].max(),
                                                    midpoint=targ_reach))
    cbr2 = fig.colorbar(sm2, cax=cax2,)
    cbr2.ax.minorticks_off()
    cbr2.ax.tick_params(labelsize=8) 

    for ax in [ax1, ax2]:
        if zoom==False:
            ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=df_reach.crs.to_string(), zoom=7)
        else:
            ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=df_reach.crs.to_string(), zoom=10)
            
    fig.tight_layout(pad=5)
    plt.savefig('figs/%s_%s.svg' % (var_reach, var_catch)) # to automatically save - can adjust dpi, etch 
    plt.show()


get_ipython().run_cell_magic("time", "", """# Plot colors by values of selected variable (`var`)


var = 'maflowv'  # Mean Annual Flow Volumentric ('maflowv')

vmin, vmax = CalcMinMax(base_reach_gdf, base_catch_gdf, var, var)

fig, (ax1, ax2) = plt.subplots(1,2)
# ax3 = fig.add_axes([0.85, 0.1, 0.1, 0.8])

r = base_reach_gdf.plot(column=var,lw=1, ax=ax1, norm=matplotlib.colors.LogNorm(vmin, vmax), cmap='RdYlGn_r') 
c = base_catch_gdf.plot(column=var, lw=0.1, ax=ax2, norm=matplotlib.colors.LogNorm(vmin, vmax), cmap='RdYlGn_r')
fig.set_size_inches(12,12)
ax1.set_title(var + " for Reaches")
ax2.set_title(var + " for Catchments")

# add colorbar 
cax = fig.add_axes([0.95, 0.22, 0.04, 0.57]) # adjusts the position of the color bar: right position, bottom, width, top 
sm = plt.cm.ScalarMappable(cmap='RdYlGn_r',
                           norm=matplotlib.colors.LogNorm(vmin=vmin, 
                                                          vmax=vmax
                                                         )
                          )
cbr = fig.colorbar(sm, cax=cax,)



for ax in [ax1, ax2]:
    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=base_catch_gdf.crs.to_string(), zoom=7)

# plt.colorbar(c, ax = ax3)
plt.show()""")


# verify that colorbars centered around correct values
print(tss_conc_target, tss_loadrate_target)


PlotMaps(base_reach_gdf, base_catch_gdf, 'tss_conc', 'tss_loadrate',  tss_conc_target, tss_loadrate_target)


clusters.plot()


print(tp_conc_target, tp_loadrate_target)


PlotMaps(base_reach_gdf, base_catch_gdf, 'tp_conc', 'tp_loadrate', tp_conc_target, tp_loadrate_target, cl=clusters.index[0])


PlotMaps(base_reach_gdf, base_catch_gdf, 'tp_conc', 'tp_loadrate', 
         tp_conc_target, tp_loadrate_target, cl=clusters.index[0], fa=True)


def LatLonExtent(cluster_name):
    lats = []
    lons = []

    values = clusters[clusters.index==cluster_name].geom_catchment.bounds
    
    y_extent = (values.maxy - values.miny) 
    x_extent = (values.maxx - values.minx) 
    
    y_extent = y_extent[0]
    x_extent = x_extent[0]
    
    aspect = (42.5 - 38.5) / (76.5 - 74)

    
    if (y_extent / x_extent) > aspect:
        lat_max = values.maxy 
        lat_min = values.miny
        
        x_tot = y_extent / aspect 
        x_pad = (x_tot - x_extent) / 2
        
        lon_max = values.maxx - x_pad
        lon_min = values.minx + x_pad
    
    elif (y_extent / x_extent) < aspect:
        print("here")
        lon_max = values.maxx 
        lon_min = values.minx 
        
        y_tot = x_extent * aspect
        y_pad = (y_tot - y_extent) / 2
        
        lat_max = values.maxy + y_pad
        lat_min = values.miny - y_pad
        
    else:
        lon_max = values.maxx + x_extent
        lon_min = values.minx - x_extent
        lat_max = values.maxy + y_extent
        lat_min = values.miny - y_extent
    
    print(aspect, (lat_max - lat_min)/(lon_max-lon_min))
    
    print(values, y_extent, x_extent, lon_max[0], lon_min[0], lat_max[0], lat_min[0])
    
    return lon_max, lon_min, lat_max, lat_min


PlotMaps(base_reach_gdf, base_catch_gdf, 'tp_conc', 'tp_loadrate', 
         tp_conc_target, tp_loadrate_target, cl=clusters.index[0], fa=True, zoom=True)


_


get_ipython().run_cell_magic("time", "", """# label focus area 
# Plot colors by values of selected variable (`var`)

var_reach = 'tp_conc'
var_catch = 'tp_load'

vmin, vmax = CalcMinMax(base_reach_gdf, base_catch_gdf, var_reach, var_catch)


fig, (ax1, ax2) = plt.subplots(1,2)
# ax3 = fig.add_axes([0.85, 0.1, 0.1, 0.8])

r = base_reach_gdf.plot(column=var_reach,lw=1, ax=ax1, norm=matplotlib.colors.LogNorm(), cmap='RdYlGn_r') 
c = base_catch_gdf.plot(column=var_catch, lw=0.1, ax=ax2, norm=matplotlib.colors.LogNorm(), cmap='RdYlGn_r')

# plot focus area 
# fa = base_gdf_catch_proj[base_gdf_catch_proj.fa_name == 'Lower/Middle Musconetcong River'].plot(lw=0.1, ax=ax2, color="black")
# cl = base_gdf_catch_proj[base_gdf_catch_proj.cluster == 'New Jersey Highlands'].plot(lw=0.1, ax=ax2)
# cl = clusters[clusters.index == 'New Jersey Highlands'].plot(lw=0.1, ax=ax2, facecolor="none", edgecolor="black")
fa = focus_areas[focus_areas.index == 'Lower/Middle Musconetcong River'].plot(lw=1, ax=ax2, facecolor="none", edgecolor="black")
fa = focus_areas[focus_areas.index == 'Lower/Middle Musconetcong River'].plot(lw=1, ax=ax1, facecolor="none", edgecolor="black")


fig.set_size_inches(10,10)
ax1.set_title("Reaches")
ax2.set_title("Catchments")

# add colorbar - catchment 
cax = fig.add_axes([0.935, 0.38, 0.03, 0.24]) # adjusts the position of the color bar: right position, bottom, width, top 

sm = plt.cm.ScalarMappable(cmap='RdYlGn_r', 
                           norm=matplotlib.colors.LogNorm(vmin=vmin, 
                                                          vmax=vmax
                                                         )
                          )

cbr = fig.colorbar(sm, cax=cax,)


# add colorbar - reach
cax2 = fig.add_axes([0.47, 0.38, 0.03, 0.24]) # adjusts the position of the color bar: right position, bottom, width, top 
sm2 = plt.cm.ScalarMappable(cmap='RdYlGn_r',
                           norm=matplotlib.colors.LogNorm(vmin=vmin, 
                                                          vmax=vmax
                                                         )
                          )
cbr2 = fig.colorbar(sm2, cax=cax2,)
cbr.ax.tick_params(labelsize=8)
cbr2.ax.minorticks_off()
cbr2.ax.tick_params(labelsize=8) 


### setting the size 
for ax in [ax1, ax2]:
    ax.set_ylim(40.5,40.75) # lat
    ax.set_xlim(-75.3, -74.95) #lon
    ctx.add_basemap(ax, source=ctx.providers.CartoDB.Positron, crs=base_reach_gdf.crs.to_string(), zoom=10) # Note: you can increase resolution of basemap with this feature
    ax.set_xticks(np.arange(-75.3, -74.9, 0.1)) # define tick frequency
    ax.set_yticks(np.arange(40.5, 40.7, 0.1))

# plt.colorbar(c, ax = ax3)
fig.tight_layout(pad=6)
plt.show()""")


base_catch_gdf.cluster.unique()


get_ipython().run_cell_magic("time", "", """# color by cluster 
fig, (ax1, ax2) = plt.subplots(1,2)
base_catch_gdf[base_catch_gdf.cluster != 'None'].plot(column = 'cluster', lw=0.1, ax=ax1)
base_catch_gdf[base_catch_gdf.cluster != 'None'].plot(column = 'fa_name', lw=0.1, ax=ax2)

fig.set_size_inches(8,8)
ax1.set_title("Cluster")
ax2.set_title("Focus Area")

ax1.set_ylim(39.5, 40.3)
ax1.set_xlim(-76, -75.5)
plt.show()""")


# %%time
fig = px.choropleth_mapbox(base_catch_gdf,
                           geojson=base_catch_gdf.geom_catchment,
                           locations=base_catch_gdf.index,
                           color='maflowv',
                           color_continuous_scale="Viridis",
                           # range_color=(0, 12),
                           mapbox_style="carto-positron",
                           zoom=6,
                           center = {"lat": 40.4604, "lon": -74.8334},
                           opacity=0.5,
                           height = 500,
                           # width = 500,
                           labels={'Comid':'comid'},
                          )
fig.update_traces(marker_line_color='rgba(255,255,255,0)', selector=dict(type='choroplethmapbox')) #make the border transparent
fig.update_layout(margin={"r":300,"t":0,"l":300,"b":0})
# fig['layout']['geo']['subunitcolor']='rgba(0,0,0,0)'

fig.show()


get_ipython().run_cell_magic("time", "", """
# plot lines https://plotly.com/python/lines-on-mapbox/
# Modified to replace np.append inside the loop with list append, which is much faster. 

import numpy as np

lats = []
lons = []
names = []
colors = []

i = 0 
tot = len(base_reach_gdf.geom)

for feature, name, mfv in zip(base_reach_gdf.geom, base_reach_gdf.index, base_reach_gdf.maflowv):

    if feature == None:
        pass
    else:
        linestrings = feature


        for linestring in linestrings:
            x, y = linestring.xy
            lats.extend(y)
            lons.extend(x)
            names.extend([name]*len(y))
            colors.extend([mfv]*len(y))
            lats.extend([None])
            lons.extend([None])
            names.extend([None])
            colors.extend([None])
    pct = round(i / tot * 100, 2)
    if pct % 10 == 0:
        print(str(pct) + "% done") 
    i += 1""")


# %%time
fig = px.line_mapbox(lat=lats, lon=lons, hover_name=names,
                     mapbox_style="carto-positron",
                     # color=colors,
                     zoom=6,
                     center = {"lat": 40.4604, "lon": -74.8334},
                     height=500
                    )
fig.update_layout(margin={"r":300,"t":0,"l":300,"b":0})
fig.show()


# set up for chloropleth map 
# geo_df_g2_json = json.loads(base_gdf_.to_json())


# %%time
# import plotly.graph_objects as go

# token = "pk.eyJ1Ijoic2pvcmRhbjI5IiwiYSI6ImNrc3Jzb2Y4ODBwbTYybnA3MjloZ2RjMHcifQ.6IVtsCFcLvhLFNl_IF9OqA"
# fig = go.Figure(go.Choroplethmapbox(geojson=geo_df_g2_json,
#                                     locations=base_gpd.index,
#                                     z = base_gpd['maflowv'],
#                                     colorscale="Viridis",
#                                     marker_line_width=0,
# #                                   #  height
#                                    ))
# fig.update_layout(mapbox_style="light", mapbox_accesstoken=token,
#                   mapbox_zoom=6, mapbox_center = {"lat": 40.4604, "lon": -74.8334})
# fig.update_layout(margin={"r":0,"t":0,"l":0,"b":0})
# fig.show()


import pandas as pd
import numpy as np
from bokeh.io import output_notebook
output_notebook()
pd.set_option('display.max_columns', 100)

from holoviews.operation.datashader import datashade
import geoviews as gv
import cartopy.crs as ccrs
from colorcet import fire

gv.extension('bokeh')


# geometry needs to be labeled as geometry with geoviews
base_catch_gdf = base_catch_gdf.rename(columns={"geom_catchment":"geometry"})


# base_gdf_catch_proj = base_gdf_catch_proj.set_geometry("geom")


# polys = gv.Polygons(base_catch_gdf, vdims=['maflowv'], crs=ccrs.PlateCarree())

# plot = gv.tile_sources.CartoDark()\
#     * polys.opts(color_index='maflowv', colorbar=True, tools=['hover'])
# plot.opts(width=700, height=600, bgcolor='black')
# #gv.save(plot, "./img/datashader/map_cologne1.html")


# conda install -c pyviz spatialpandas
# conda install -c conda-forge pygeos
# conda install -c conda-forge geopandas=0.8.0 : https://githubmemory.com/repo/holoviz/spatialpandas/issues/58
import spatialpandas as spd
import spatialpandas.io
import pygeos
import datashader as ds
# ddf = spd.io.read_parquet_dask('./data/base_df.parquet')


arr_sp = spatialpandas.geometry.MultiPolygonArray.from_geopandas(base_catch_gdf.geometry, orient=False)


df_spd = spatialpandas.GeoDataFrame(base_catch_gdf)


df_spd = df_spd.rename(columns={'geom_catchment': 'geometry'})


df_spd = df_spd.set_geometry("geometry")


# df_spd['geometry'] = df_spd['geometry'].astype(np.float32)


df_spd.head()



# try datashader on polygons:

cvs = ds.Canvas(plot_width=650, plot_height=400)
agg = cvs.polygons(df_spd, geometry='geometry', agg=ds.mean("maflowv"))
ds.transfer_functions.shade(agg)


def get_flat_coords_offset_arrays(arr):
    """
    Version for MultiPolygon data
    """
    # explode/flatten the MultiPolygons
    arr_flat, part_indices = pygeos.get_parts(arr, return_index=True)
    # the offsets into the multipolygon parts
    offsets1 = np.insert(np.bincount(part_indices).cumsum(), 0, 0)

    # explode/flatten the Polygons into Rings
    arr_flat2, ring_indices = pygeos.geometry.get_rings(arr_flat, return_index=True)
    # the offsets into the exterior/interior rings of the multipolygon parts 
    offsets2 = np.insert(np.bincount(ring_indices).cumsum(), 0, 0)

    # the coords and offsets into the coordinates of the rings
    coords, indices = pygeos.get_coordinates(arr_flat2, return_index=True)
    offsets3 = np.insert(np.bincount(indices).cumsum(), 0, 0)
    
    return coords, offsets1, offsets2, offsets3

def spatialpandas_from_pygeos(arr):
    coords, offsets1, offsets2, offsets3 = get_flat_coords_offset_arrays(arr)
    coords_flat = coords.ravel()
    offsets3 *= 2
    
    # create a pyarrow array from this
    _parr3 = pa.ListArray.from_arrays(pa.array(offsets3), pa.array(coords_flat))
    _parr2 = pa.ListArray.from_arrays(pa.array(offsets2), _parr3)
    parr = pa.ListArray.from_arrays(pa.array(offsets1), _parr2)
    
    return spatialpandas.geometry.MultiPolygonArray(parr)


base_gdf_catch.info()


base_gdf_catch.geom_catchment.array.data


arr_sp2 = spatialpandas_from_pygeos(base_gdf_catch.geom_catchment.array.data)



